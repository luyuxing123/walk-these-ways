11-06：训练基本按照xyf的奖励函数来，没有实现gait endoer和generator，直接将gt作为actor和critic输入
3万轮，效果还行

11-07：所有奖励函数完全按照xyf的，唯一的不同是没有amp部分的奖励函数u
两万轮效果还行，但是3万效果特别差，无法行走

11-10：加上了amp的奖励函数以及判别器的目标函数，可是效果似乎不太好，使用的是wjz的轨迹

11-11：使用自己生成的轨迹重新训练
感觉还是不好

使用wjz的轨迹，并且添加        lin_vel_z = -0.02 ，ang_vel_xy = -0.001 ，orientation = -0.5

感觉不好，增大奖励，        lin_vel_z = -0.5 ，ang_vel_xy = -0.05 ，orientation = -0.5

11-12：完全按照11-06来，但是足端力和速度的奖励减小到0.5
效果还可以

11-13：在上一个基础上，添加amp,足端力、速度恢复到1
感觉不好呢？这个相比11-11最后一个只是添加了raibert

去掉raibert重新训练,感觉似乎可以了

只训练上楼梯。之前是上下楼梯交替，越过当前障碍可以前往下一个，但是下楼梯比上楼梯容易，如果前一个是下楼梯，后一个是上楼梯，那么可能agent没有学会前一个
的上楼梯，对策略产生不好的影响。其余均和11-12一样，足端力、速度为0.5，raibert为-1.
根据代码terrain type没有发生变化，所以前一个是下楼梯，后一个是上楼梯，依次交替。所以可能只学会了前一个的下楼梯并没有学会前一个的上楼梯

11-14:
请脚薛宇斐，发现楼梯宽度不能设置为固定的，否则会过度拟合仿真环境的楼梯，即使完全按照真实宽度设置，由于sim2real有gap，所以效果不好
应该使用多种宽度的楼梯，让他各种地形都见过
感觉足端力、速度这个比较低，有一只脚经常打滑

11-15：足端力、速度改为1，其余不变
修改adaptation module，隐藏层和history encoder一致

11-16：按照wjz teacher student修改obs的噪声幅度，且将足端力、速度修改为0.5
好像不是足端力、速度的原因，感觉修改了adaptation module之后触地力就特别大

adaptation修改回去64，32.输入ht输出vt（最开始是输入obs history输出vt，与wjz论文不一致）
足端力、速度修改回1
ht输入，64，32，vt输出感觉效果不好

仅修改输入为obs history.
这次隐藏层为64，32，输入为obs history，足端力、速度为1，相比11-14修改了obs的noise

11-17
去除足端力、速度奖励，raibert，以及z线速度，xy角速度，仅保留论文中相关的，按照xyf的说法，amp使用的是非常隐式的奖励，walk-these-ways使用的是
非常显式的奖励，所以使用amp感觉效果不明显。

11-18:猜测触地力很大是因为只有上楼梯。
修改为一个上一个下交替，且level数量为之前二倍
xyf说0.004线速度估计不是狠准，于是adaptation网络结构还是改回256，128
破案了，就是因为只有上楼梯，导致触地力很大

11-19：
添加论文的部分，forward和inverse网路
奖励函数权重为1e-5

forward和inverse网路结构修改为256，128
效果不好

网络结构改回去，ang_vel_xy改为-0.5

11-20:forward和inverse奖励权重应该是正的，预测的与真实的不一致时被鼓励，鼓励探索

改为1e-4，完全不行

1e-6




